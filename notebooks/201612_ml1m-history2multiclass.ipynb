{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-02-11 16:13:22--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Resolving files.grouplens.org... 128.101.34.146\n",
      "Connecting to files.grouplens.org|128.101.34.146|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5917549 (5.6M) [application/zip]\n",
      "Saving to: '/Users/gui/Data/ml-1m.zip.1'\n",
      "\n",
      "ml-1m.zip.1         100%[=====================>]   5.64M  1.67MB/s   in 3.7s   \n",
      "\n",
      "2017-02-11 16:13:26 (1.51 MB/s) - '/Users/gui/Data/ml-1m.zip.1' saved [5917549/5917549]\n",
      "\n",
      "Archive:  /Users/gui/Data/ml-1m.zip\n",
      "replace /Users/gui/Data/ml-1m/movies.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "#! wget http://files.grouplens.org/datasets/movielens/ml-1m.zip --directory-prefix /Users/gui/Data/\n",
    "#! unzip /Users/gui/Data/ml-1m.zip -d /Users/gui/Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathbf{Y}^\\top = \\mathbf{R} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = (pd.read_csv('/Users/gui/Data/ml-1m/ratings.dat', engine='python', sep='::', names=['user', 'item', 'rating', 'timestamp'])\n",
    "    .assign(timestamp=lambda df:pd.to_datetime(df.timestamp * 1000000000)))\n",
    "\n",
    "movies = (pd.read_csv('/Users/gui/Data/ml-1m/movies.dat', engine='python', sep='::', names=['item', 'title', 'genres'])\n",
    "          .assign(genres=lambda df:df.genres.str.split('|').values)\n",
    "          .set_index('item', drop=False))\n",
    "\n",
    "# See http://files.grouplens.org/datasets/movielens/ml-1m-README.txt for more details\n",
    "users = pd.read_csv('/Users/gui/Data/ml-1m/users.dat', engine='python', sep='::', \n",
    "                    names=['user', 'gender', 'age', 'occupation', 'zipcode'])\\\n",
    "    .set_index('user', drop=False)\n",
    "\n",
    "N_USERS, N_ITEMS = users.user.max() + 1, movies.item.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900209, 4)\n",
      "(100000, 4)\n",
      "(23876120, 2)\n",
      "(5941,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  user\n",
       "0     0     1\n",
       "1     1     1\n",
       "2     2     1\n",
       "3     3     1\n",
       "4     4     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = ratings.sample(n=100000, random_state=0).sort_index()\n",
    "test_sample_ids = test_df.index.values\n",
    "train_ratings_mask = ~ratings.index.isin(test_sample_ids)\n",
    "train_df = ratings.loc[train_ratings_mask]\n",
    "train_sample_ids = train_df.index.values\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "test_user_ids = test_df.user.unique()\n",
    "all_user_ids = train_df.user.unique()\n",
    "all_item_ids = np.arange(N_ITEMS)\n",
    "\n",
    "def to_all_user_items(user_ids, item_ids):\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {'user': np.repeat(user_ids, len(item_ids)),\n",
    "         'item': np.tile(item_ids, len(user_ids))})\n",
    "\n",
    "all_user_items = to_all_user_items(all_user_ids, all_item_ids)\n",
    "print(all_user_items.shape)\n",
    "print(test_user_ids.shape)\n",
    "all_user_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user features = <6041x9 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 12080 stored elements in Compressed Sparse Row format>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>feature</th>\n",
       "      <th>encoded_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gender=F</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>age=1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gender=M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>age=56</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>gender=M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user   feature  encoded_feature\n",
       "0     1  gender=F                7\n",
       "1     1     age=1                0\n",
       "2     2  gender=M                8\n",
       "3     2    age=56                6\n",
       "4     3  gender=M                8"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def columns_to_key_feature_pairs(row, key_column, feature_columns):\n",
    "    return [(row[key_column], '{}={}'.format(column, row[column])) for column in feature_columns]\n",
    "\n",
    "feature_columns=['gender', 'age']#'user', 'zipcode']\n",
    "\n",
    "user_features_df = pd.DataFrame.from_records(\n",
    "    data=chain.from_iterable(\n",
    "        columns_to_key_feature_pairs(row, key_column='user', feature_columns=feature_columns)\n",
    "        for _, row in users.iterrows()),\n",
    "    columns=['user', 'feature'])\\\n",
    "    .assign(feature=lambda df: df.feature.astype('category'))\\\n",
    "    .assign(encoded_feature=lambda df: df.feature.values.codes)\n",
    "\n",
    "user_features = sparse.csr_matrix((np.ones_like(user_features_df.user), (user_features_df.user, user_features_df.encoded_feature)))\n",
    "print('user features = %s' % user_features.__repr__())    \n",
    "\n",
    "N_USER_FEATURES = user_features.shape[1]\n",
    "user_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age=1</th>\n",
       "      <th>age=18</th>\n",
       "      <th>age=25</th>\n",
       "      <th>age=35</th>\n",
       "      <th>age=45</th>\n",
       "      <th>age=50</th>\n",
       "      <th>age=56</th>\n",
       "      <th>gender=F</th>\n",
       "      <th>gender=M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age=1  age=18  age=25  age=35  age=45  age=50  age=56  gender=F  \\\n",
       "user                                                                    \n",
       "1         1       0       0       0       0       0       0         1   \n",
       "2         0       0       0       0       0       0       1         0   \n",
       "6038      0       0       0       0       0       0       1         1   \n",
       "\n",
       "      gender=M  \n",
       "user            \n",
       "1            0  \n",
       "2            1  \n",
       "6038         0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = [1, 2, 6038]\n",
    "\n",
    "pd.DataFrame(\n",
    "    index=pd.Index(user_ids, name='user'),\n",
    "    data=user_features[user_ids].toarray(),\n",
    "    columns=user_features_df.feature.values.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user history features = <6041x3954 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 523991 stored elements in Compressed Sparse Row format>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:33:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:11:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating           timestamp\n",
       "0     1  1193       5 2000-12-31 22:12:40\n",
       "3     1  3408       4 2000-12-31 22:04:35\n",
       "4     1  2355       5 2001-01-06 23:38:11\n",
       "6     1  1287       5 2000-12-31 22:33:59\n",
       "7     1  2804       5 2000-12-31 22:11:59"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_views = train_df.query('rating > 3')\n",
    "user_history_features = sparse.csr_matrix(\n",
    "    (np.ones_like(positive_views.user), \n",
    "    (positive_views.user, positive_views.item)),\n",
    "    shape=(N_USERS, N_ITEMS))\n",
    "\n",
    "# To make sure every user has a feature\n",
    "user_default_feature = sparse.coo_matrix(np.ones(N_USERS).reshape(-1, 1))\n",
    "user_history_features = sparse.hstack([user_history_features, user_default_feature]).tocsr()\n",
    "\n",
    "N_USER_HISTORY_FEATURES = user_history_features.shape[1]\n",
    "\n",
    "print('user history features = %s' % user_history_features.__repr__())    \n",
    "\n",
    "positive_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3944</th>\n",
       "      <th>3945</th>\n",
       "      <th>3946</th>\n",
       "      <th>3947</th>\n",
       "      <th>3948</th>\n",
       "      <th>3949</th>\n",
       "      <th>3950</th>\n",
       "      <th>3951</th>\n",
       "      <th>3952</th>\n",
       "      <th>3953</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 3954 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item  0     1     2     3     4     5     6     7     8     9     ...   3944  \\\n",
       "user                                                              ...          \n",
       "1        0     1     0     0     0     0     0     0     0     0  ...      0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "6038     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "item  3945  3946  3947  3948  3949  3950  3951  3952  3953  \n",
       "user                                                        \n",
       "1        0     0     0     0     0     0     0     0     1  \n",
       "2        0     0     0     0     0     0     0     0     1  \n",
       "6038     0     0     0     0     0     0     0     0     1  \n",
       "\n",
       "[3 rows x 3954 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = [1, 2, 6038]\n",
    "\n",
    "pd.DataFrame(\n",
    "    index=pd.Index(user_ids, name='user'),\n",
    "    data=np.asarray(user_history_features[user_ids].toarray(), dtype=np.int64),\n",
    "    columns=pd.Index(np.arange(user_history_features.shape[1]), name='item'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1357</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 21:38:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>1419</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-26 02:06:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item  rating           timestamp\n",
       "user                                  \n",
       "1     1193       5 2000-12-31 22:12:40\n",
       "2     1357       5 2000-12-31 21:38:29\n",
       "6038  1419       4 2000-04-26 02:06:55"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.set_index('user').loc[[1, 2, 6038]].reset_index().groupby('user').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6038.000000\n",
       "mean       85.781716\n",
       "std        94.441821\n",
       "min         1.000000\n",
       "25%        25.000000\n",
       "50%        52.000000\n",
       "75%       111.000000\n",
       "max      1292.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_views.groupby('user').size().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensforflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensorValue(indices=array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [0, 4],\n",
       "       [0, 5]]), values=array([1210, 2700, 2800, 3000, 3704, 3953], dtype=int32), shape=(1, 3954))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intra_row_index(row_indexes):\n",
    "    count_by_row = np.bincount(row_indexes)\n",
    "    shift_by_row = np.concatenate([[0], np.cumsum(count_by_row)])\n",
    "    return np.arange(len(row_indexes)) - shift_by_row[row_indexes]\n",
    "\n",
    "# from https://github.com/tensorflow/tensorflow/issues/342#issuecomment-160354041\n",
    "# not very sparse, but rather a kind of jagged array where every batch sample can have 1, N_FEATURES features\n",
    "def sparse_features_to_tensor(batch_sparse_features):\n",
    "    batch_features_as_coo = batch_sparse_features.tocoo()\n",
    "    batch_features_sparse_tensor = tf.SparseTensorValue(\n",
    "        indices=np.vstack([batch_features_as_coo.row, intra_row_index(batch_features_as_coo.row)]).T,\n",
    "        values=batch_features_as_coo.col,\n",
    "        shape=batch_features_as_coo.shape\n",
    "    )\n",
    "    return batch_features_sparse_tensor\n",
    "\n",
    "sparse_features_to_tensor(user_history_features[21,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_predictions_to_hits(all_user_items, all_predicted_values, ground_truth_user_items):\n",
    "    predicted_ratings = all_user_items.assign(predicted_rating=lambda _: all_predicted_values)\n",
    "    predicted_ranks = predicted_ratings.groupby('user')['predicted_rating'].rank(ascending=False, method='max')\n",
    "    predicted_ratings['rank'] = predicted_ranks.values - 1\n",
    "\n",
    "    ground_truth_hits = pd.merge(\n",
    "        left=ground_truth_user_items,\n",
    "        right=predicted_ratings,\n",
    "        on=['user', 'item'], how='left')\n",
    "    return ground_truth_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(predicted_ranks_df):\n",
    "    return predicted_ranks_df\\\n",
    "        .assign(rec_rank=lambda df:1 / (df['rank'] + 1))\\\n",
    "        .groupby('user')['rec_rank'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Step 0: batch/test log loss = 8.284/8.173, train/test MRR = 0.225/0.047\n",
      "Step 20: batch/test log loss = 7.331/7.311, train/test MRR = 0.601/0.131\n",
      "Step 40: batch/test log loss = 7.195/7.175, train/test MRR = 0.647/0.144\n",
      "Step 60: batch/test log loss = 7.149/7.036, train/test MRR = 0.664/0.140\n",
      "Step 80: batch/test log loss = 7.128/7.054, train/test MRR = 0.678/0.150\n",
      "Step 100: batch/test log loss = 7.027/7.049, train/test MRR = 0.691/0.146\n",
      "Step 120: batch/test log loss = 7.036/7.003, train/test MRR = 0.688/0.145\n",
      "Step 140: batch/test log loss = 7.032/6.993, train/test MRR = 0.694/0.142\n",
      "Step 160: batch/test log loss = 7.048/6.967, train/test MRR = 0.683/0.149\n",
      "Step 180: batch/test log loss = 6.977/7.097, train/test MRR = 0.673/0.150\n",
      "Step 200: batch/test log loss = 6.957/6.938, train/test MRR = 0.704/0.147\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Placeholders:\n",
    "    \n",
    "    def __init__(self, batch_size=None):\n",
    "        self.user_sparse_features = tf.sparse_placeholder(tf.int32, name='user_features')\n",
    "        self.user_sparse_history = tf.sparse_placeholder(tf.int32, name='user_history')\n",
    "        self.item_ids = tf.placeholder(tf.int32, shape=[batch_size], name='item_ids')\n",
    "\n",
    "    def to_feed_dict(self, user_items_df, with_output_item_ids=True):\n",
    "        features_dict = {\n",
    "            self.user_sparse_history: sparse_features_to_tensor(user_history_features[user_items_df.user.values,:]),\n",
    "            self.user_sparse_features: sparse_features_to_tensor(user_features[user_items_df.user.values,:])\n",
    "        }\n",
    "        \n",
    "        if with_output_item_ids:\n",
    "            features_dict[self.item_ids] = user_items_df.item.values\n",
    "\n",
    "        return features_dict\n",
    "\n",
    "\n",
    "class UserFeatures2MultiClassItemsModel:\n",
    "    def __init__(self, history_dim, demo_dim, items_dim):\n",
    "        self.history_dim = history_dim\n",
    "        self.demo_dim = demo_dim\n",
    "        self.items_dim = items_dim\n",
    "        \n",
    "        with tf.name_scope('BI'):\n",
    "            self.item_biases =  tf.Variable(tf.random_normal(shape=[N_ITEMS], stddev=0.01, mean=0), name='item_biases')\n",
    "            tf.summary.histogram('item_biases', self.item_biases)\n",
    "\n",
    "        with tf.name_scope('Q'):\n",
    "            self.user_features_factors = tf.Variable(tf.random_normal([N_USER_FEATURES, self.demo_dim], stddev=0.01, mean=0), \n",
    "                                                     name='user_features_factors')\n",
    "            tf.summary.histogram('user_features_factors', self.user_features_factors)\n",
    "\n",
    "        with tf.name_scope('H'):\n",
    "            self.user_history_factors = tf.Variable(tf.random_normal([N_USER_HISTORY_FEATURES, self.history_dim], stddev=0.01, mean=0),\n",
    "                                                     name='user_history_factors')\n",
    "            tf.summary.histogram('user_history_factors', self.user_history_factors)\n",
    "       \n",
    "        with tf.name_scope('P'):\n",
    "            self.item_factors = tf.Variable(tf.random_normal([N_ITEMS, self.items_dim], stddev=0.01, mean=0), name='item_factors')\n",
    "            tf.summary.histogram('item_factors', self.item_factors)\n",
    "            \n",
    "    def predictions(self, user_sparse_features, user_sparse_history):\n",
    "        with tf.name_scope('inference'):\n",
    "            with tf.name_scope('Q_user'):\n",
    "                batch_user_features_factors = tf.squeeze(tf.nn.embedding_lookup_sparse(\n",
    "                            self.user_features_factors,\n",
    "                            sp_ids=user_sparse_features, sp_weights=None, combiner='sum'))\n",
    "            with tf.name_scope('H_user'):\n",
    "                batch_user_history_factors = tf.squeeze(tf.nn.embedding_lookup_sparse(\n",
    "                            self.user_history_factors,\n",
    "                            sp_ids=user_sparse_history, sp_weights=None, combiner='sum'))\n",
    "            \n",
    "            \n",
    "            with tf.name_scope('QH_user'):\n",
    "                #batch_user_factors = tf.add(batch_user_features_factors, batch_user_history_factors, name='added_factors')\n",
    "                batch_concat_user_factors = tf.concat(1, (batch_user_features_factors, batch_user_history_factors),\n",
    "                                               name='concatenated_factors')\n",
    "                \n",
    "            with tf.name_scope('ReLU_user'):\n",
    "                fully_connected_weights = tf.Variable(tf.random_normal([self.history_dim + self.demo_dim, self.items_dim]))\n",
    "                fully_connected_biases = tf.Variable(tf.random_normal([self.items_dim]))\n",
    "                batch_user_factors = tf.nn.relu(\n",
    "                    tf.add(tf.matmul(batch_concat_user_factors, fully_connected_weights), fully_connected_biases))\n",
    "\n",
    "            with tf.name_scope('Logits_user_items'):\n",
    "                return tf.matmul(batch_user_factors, tf.transpose(self.item_factors)) + self.item_biases\n",
    "\n",
    "def cross_entropy_loss(logits, target_item_ids):\n",
    "    with tf.name_scope('cross_entropy_loss'):\n",
    "        return tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits,\n",
    "                labels=target_item_ids))\n",
    "    \n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "N_ITER = 201\n",
    "BATCH_SIZE = 1024\n",
    "N_STEP_SUMMARY = 20\n",
    "\n",
    "LOG_DIR = '/tmp/tfrecs_logs'\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    inputs = Placeholders()\n",
    "        \n",
    "    model = UserFeatures2MultiClassItemsModel(history_dim=20, demo_dim=20, items_dim=20)\n",
    "    logits = model.predictions(inputs.user_sparse_features, inputs.user_sparse_history)\n",
    "    loss = cross_entropy_loss(logits, inputs.item_ids)\n",
    "        \n",
    "    tf.summary.scalar('train_loss', loss)\n",
    "    summary = tf.summary.merge_all()\n",
    "    test_summary = tf.summary.scalar('test_loss', loss)\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "    def perform_step(step, train, test, summary_writer):\n",
    "        # positive only sampling\n",
    "        batch_samples = train_df.query(\"rating > 3\").sample(BATCH_SIZE)\n",
    "\n",
    "        _, loss_value, summary_value = sess.run(\n",
    "            fetches=[train_step, loss, summary], \n",
    "            feed_dict=inputs.to_feed_dict(batch_samples))\n",
    "        \n",
    "        summary_writer.add_summary(summary_value, global_step=step)\n",
    "\n",
    "        if step % N_STEP_SUMMARY == 0:\n",
    "            test_samples = train_df.query(\"rating > 3\").sample(BATCH_SIZE)\n",
    "            test_loss_value, test_summary_value = sess.run(\n",
    "                fetches=[loss, test_summary],\n",
    "                feed_dict=inputs.to_feed_dict(test_samples))\n",
    "            summary_writer.add_summary(test_summary_value, global_step=step)\n",
    "\n",
    "            # predicting on all users\n",
    "            all_prediction_values = logits.eval(inputs.to_feed_dict(pd.DataFrame.from_dict({'user':all_user_ids}),\n",
    "                                                                    with_output_item_ids=False)).ravel()\n",
    "            \n",
    "            print('Step %d: batch/test log loss = %.3f/%.3f, train/test MRR = %.3f/%.3f' % (\n",
    "                    step, loss_value, test_loss_value, \n",
    "                    mean_reciprocal_rank(all_predictions_to_hits(\n",
    "                        all_user_items, all_prediction_values, train_df.query(\"rating > 3\"))).mean(),\n",
    "                    mean_reciprocal_rank(all_predictions_to_hits(\n",
    "                        all_user_items, all_prediction_values, test_df.query(\"rating > 3\"))).mean()\n",
    "                ))\n",
    "\n",
    "        summary_writer.flush()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(LOG_DIR + '/{:%Y%m%d%H%M%S}'.format(dt.datetime.now()), sess.graph)\n",
    "\n",
    "        print('Starting training')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for step in range(N_ITER):\n",
    "            perform_step(step, train_df, test_df, summary_writer)\n",
    "        \n",
    "        # would like to have the binding tensor - ids somewhere else\n",
    "        item_factors_df = pd.DataFrame(index=np.arange(N_ITEMS), data=model.item_factors.eval())\n",
    "        user_features_factors_df = pd.DataFrame(index=np.arange(N_USER_FEATURES), data=model.user_features_factors.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting embeddings for later visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3892, 3)\n",
      "(3892, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "individual_user_features = pd.DataFrame(user_features_df.feature.values.categories, columns=['feature'])\\\n",
    "    .assign(title=lambda df:df.feature)\n",
    "subset_individual_user_features = individual_user_features[~individual_user_features.feature.str.startswith('user=')]\n",
    "\n",
    "subset_item_features = movies.assign(feature=lambda df: 'genre=' + df.genres.str[0])[['title', 'feature']]\n",
    "\n",
    "\n",
    "# Cannot export embeddings for non tf.Variable tensors, so doing it manually\n",
    "concatenated_metadata = pd.concat([\n",
    "    subset_individual_user_features.assign(feature_type=lambda _: 'user_based'),\n",
    "    subset_item_features.assign(feature_type=lambda _: 'item_based')],\n",
    "    ignore_index=True)\n",
    "\n",
    "concatenated_factors = pd.concat([\n",
    "    user_features_factors_df.loc[subset_individual_user_features.index], \n",
    "    item_factors_df.loc[subset_item_features.index]],\n",
    "    ignore_index=True)\n",
    "\n",
    "\n",
    "class ProjectorConfig:\n",
    "    root_url = 'https://raw.githubusercontent.com/pilipolio/tfrecs/master/embeddings/'\n",
    "    local_root = '../embeddings'\n",
    "\n",
    "    @classmethod\n",
    "    def save_projector_config(cls, name, metadata_df, tensor_df):\n",
    "        print(metadata_df.shape)\n",
    "        print(tensor_df.shape)\n",
    "        \n",
    "        metadata_filename = name + '_metadata.tsv'\n",
    "        metadata_df.to_csv(os.path.join(cls.local_root, metadata_filename), sep='\\t', index=None)\n",
    "\n",
    "        tensor_filename = name + '.tsv'\n",
    "        tensor_df.to_csv(os.path.join(cls.local_root, tensor_filename), sep='\\t', index=None, header=None)\n",
    "        \n",
    "        projector_config_dict = {\n",
    "            'embeddings': [\n",
    "            {\n",
    "                \"metadataPath\": os.path.join(cls.root_url, metadata_filename),\n",
    "                'tensorName': name,\n",
    "                'tensorShape': tensor_df.shape,\n",
    "                'tensorPath': os.path.join(cls.root_url, tensor_filename)\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(cls.local_root, name + '_projector_config.json'), 'w') as f:\n",
    "            json.dump(projector_config_dict, f)\n",
    "    \n",
    "ProjectorConfig.save_projector_config('ml1m_user_items', concatenated_metadata, concatenated_factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>16890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drama</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Action</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Romance</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Horror</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children's</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Crime</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>War</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Musical</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animation</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Western</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          genre  count\n",
       "3          None  16890\n",
       "7         Drama   1603\n",
       "2        Comedy   1200\n",
       "8        Action    503\n",
       "10     Thriller    492\n",
       "6       Romance    471\n",
       "11       Horror    343\n",
       "4     Adventure    283\n",
       "12       Sci-Fi    276\n",
       "1    Children's    251\n",
       "9         Crime    211\n",
       "14          War    143\n",
       "13  Documentary    127\n",
       "15      Musical    114\n",
       "16      Mystery    106\n",
       "0     Animation    105\n",
       "5       Fantasy     68\n",
       "18      Western     68\n",
       "17    Film-Noir     44"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "pd.DataFrame.from_records(list(collections.Counter(chain.from_iterable(pd.DataFrame(movies.genres.tolist()).values)).items()),\n",
    "                         columns=['genre', 'count']).sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age=18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age=25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age=35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age=45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age=50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age=56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gender=F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender=M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature\n",
       "0     age=1\n",
       "1    age=18\n",
       "2    age=25\n",
       "3    age=35\n",
       "4    age=45\n",
       "5    age=50\n",
       "6    age=56\n",
       "7  gender=F\n",
       "8  gender=M"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_individual_user_features"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
