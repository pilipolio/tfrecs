{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allaingu/miniconda3/envs/gui/lib/python3.6/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train\n",
      "[1 2 3 4 5]\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 90570 stored elements in COOrdinate format>\n",
      "original test\n",
      "[1 2 3 4 5]\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 9430 stored elements in COOrdinate format>\n",
      "train\n",
      "[-1  1]\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 90570 stored elements in COOrdinate format>\n",
      "test\n",
      "[-1  1]\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 9430 stored elements in COOrdinate format>\n",
      "test_positive_only\n",
      "[1]\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 5469 stored elements in COOrdinate format>\n",
      "There are 1701 distinct item features, with values like ['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)'].\n",
      "There are 943 distinct user features.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from lightfm.datasets import fetch_movielens\n",
    "\n",
    "data = fetch_movielens('movielens', indicator_features=True, genre_features=True)\n",
    "\n",
    "print('original train')\n",
    "print(np.unique(data['train'].data))\n",
    "print(data['train'].__repr__())\n",
    "print('original test')\n",
    "print(np.unique(data['test'].data))\n",
    "print(data['test'].__repr__())\n",
    "\n",
    "# binarizing training examples as in the original lightfm paper to use the logistic loss\n",
    "data['train'].data = np.array([-1, 1])[1 * (data['train'].data >= 4)]\n",
    "data['test'].data = np.array([-1, 1])[1 * (data['test'].data >= 4)]\n",
    "\n",
    "# should keep only positive test interactions\n",
    "data['test_positive_only'] = data['test'].copy()\n",
    "data['test_positive_only'].data = 1 *(data['test_positive_only'].data>=1)\n",
    "data['test_positive_only'].eliminate_zeros()\n",
    "\n",
    "train = data['train']\n",
    "test = data['test']\n",
    "test_positives = data['test_positive_only']\n",
    "\n",
    "print('train')\n",
    "print(np.unique(data['train'].data))\n",
    "print(data['train'].__repr__())\n",
    "print('test')\n",
    "print(np.unique(data['test'].data))\n",
    "print(data['test'].__repr__())\n",
    "print('test_positive_only')\n",
    "print(np.unique(data['test_positive_only'].data))\n",
    "print(data['test_positive_only'].__repr__())\n",
    "\n",
    "item_features = data['item_features']\n",
    "tag_labels = data['item_feature_labels']\n",
    "print('There are %s distinct item features, with values like %s.' % (item_features.shape[1], tag_labels[:3].tolist()))\n",
    "\n",
    "# indicator only user features\n",
    "unique_user_ids = np.unique(train.row)\n",
    "user_features = sparse.csr_matrix((np.ones_like(unique_user_ids), (unique_user_ids, unique_user_ids)))\n",
    "print('There are %s distinct user features.' % user_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(predicted_ranks_df):\n",
    "    return predicted_ranks_df.assign(rec_rank=lambda df:1 / (df['rank'] + 1)).groupby('user')['rec_rank'].max().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensforflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 3)\n",
      "(1586126, 2)\n",
      "(943,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item\n",
       "0     0     0\n",
       "1     0     1\n",
       "2     0     2\n",
       "3     0     3\n",
       "4     0     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame.from_dict({\n",
    "        'user': train.row,\n",
    "        'item': train.col,\n",
    "        'rating': train.data,\n",
    "    })\n",
    "\n",
    "test_df = pd.DataFrame.from_dict({\n",
    "        'user': test.row,\n",
    "        'item': test.col,\n",
    "        'rating': test.data,\n",
    "    })\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()\n",
    "\n",
    "test_user_ids = test_df.user.unique()\n",
    "all_user_ids = train_df.user.unique()\n",
    "all_item_ids = np.unique(data['item_features'].tocoo().row)\n",
    "\n",
    "def to_all_user_items(user_ids, item_ids):\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {'user': np.repeat(user_ids, len(item_ids)),\n",
    "         'item': np.tile(item_ids, len(user_ids))})\n",
    "\n",
    "all_user_items = to_all_user_items(all_user_ids, all_item_ids)\n",
    "print(all_user_items.shape)\n",
    "print(test_user_ids.shape)\n",
    "all_user_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features[train_df.tail().user.values,:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensorValue(indices=array([[0, 0],\n",
       "       [1, 0],\n",
       "       [2, 0],\n",
       "       [3, 0],\n",
       "       [4, 0]]), values=array([942, 942, 942, 942, 942], dtype=int32), dense_shape=(5, 943))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intra_row_index(row_indexes):\n",
    "    count_by_row = np.bincount(row_indexes)\n",
    "    shift_by_row = np.concatenate([[0], np.cumsum(count_by_row)])\n",
    "    return np.arange(len(row_indexes)) - shift_by_row[row_indexes]\n",
    "\n",
    "# from https://github.com/tensorflow/tensorflow/issues/342#issuecomment-160354041\n",
    "# not very sparse, but rather a kind of jagged array where every batch sample can have 1, N_FEATURES features\n",
    "def sparse_features_to_tensor(batch_sparse_features):\n",
    "    batch_features_as_coo = batch_sparse_features.tocoo()\n",
    "    batch_features_sparse_tensor = tf.SparseTensorValue(\n",
    "        indices=np.vstack([batch_features_as_coo.row, intra_row_index(batch_features_as_coo.row)]).T,\n",
    "        values=batch_features_as_coo.col,\n",
    "        dense_shape=batch_features_as_coo.shape\n",
    "    )\n",
    "    return batch_features_sparse_tensor\n",
    "\n",
    "sparse_features_to_tensor(user_features[train_df.tail().user.values,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(positives_df, batch_size, positive_ratio=.33):\n",
    "    n_positives = int(batch_size * positive_ratio)\n",
    "    n_negatives = batch_size - n_positives\n",
    "    negatives = pd.DataFrame.from_dict({\n",
    "        'user': np.random.choice(all_user_ids, replace=True, size=n_negatives),\n",
    "        'item': np.random.choice(all_item_ids, replace=True, size=n_negatives),\n",
    "        'rating': np.repeat(0, n_negatives)\n",
    "        })\n",
    "    return pd.concat([positives_df.sample(n_positives), negatives], axis=0)\n",
    "\n",
    "# if train has both positives and negatives\n",
    "def sample_batch(positives_and_negatives_df, batch_size):\n",
    "    batch_df = positives_and_negatives_df.sample(batch_size)\n",
    "    return batch_df.assign(rating = lambda df: np.maximum(df.rating, 0))\n",
    "\n",
    "test_samples = sample_batch(train_df, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USERS, N_ITEMS = train.shape\n",
    "N_ITEM_FEATURES = item_features.shape[1]\n",
    "N_USER_FEATURES = user_features.shape[1]\n",
    "\n",
    "class Placeholders:\n",
    "    \n",
    "    def __init__(self, batch_size=None):\n",
    "        self.user_sparse_features = tf.sparse_placeholder(tf.int32, name='user_features')\n",
    "        self.item_sparse_features = tf.sparse_placeholder(tf.int32, name='item_features')\n",
    "        self.ratings = tf.placeholder(tf.float32, shape=[batch_size], name='ratings')\n",
    "\n",
    "    def to_feed_dict(self, user_items_df, with_ratings=False):\n",
    "        features_dict = {\n",
    "            self.item_sparse_features: sparse_features_to_tensor(item_features[user_items_df.item.values,:]),\n",
    "            self.user_sparse_features: sparse_features_to_tensor(user_features[user_items_df.user.values,:])\n",
    "            }\n",
    "        \n",
    "        if with_ratings:\n",
    "            features_dict[self.ratings] = user_items_df.rating.values\n",
    "\n",
    "        return features_dict\n",
    "    \n",
    "    \n",
    "class UserItemFeaturesModel:\n",
    "    def __init__(self, dimensionality=30):\n",
    "        self.dimensionality = dimensionality\n",
    "    \n",
    "        with tf.name_scope('BU'):\n",
    "            self.user_features_biases =  tf.Variable(tf.random_normal(shape=[N_USER_FEATURES, 1], stddev=0.01, mean=0))\n",
    "            tf.summary.histogram('user_features_biases', self.user_features_biases)\n",
    "\n",
    "        with tf.name_scope('BI'):\n",
    "            self.item_features_biases =  tf.Variable(tf.random_normal(shape=[N_ITEM_FEATURES, 1], stddev=0.01, mean=0))\n",
    "            tf.summary.histogram('item_features_biases', self.item_features_biases)\n",
    "\n",
    "        with tf.name_scope('Q'):\n",
    "            self.user_features_factors = tf.Variable(tf.random_normal([N_USER_FEATURES, self.dimensionality], stddev=0.01, mean=0))\n",
    "            tf.summary.histogram('user_features_factors', self.user_features_factors)\n",
    "            \n",
    "        with tf.name_scope('P'):\n",
    "            self.item_features_factors = tf.Variable(tf.random_normal([N_ITEM_FEATURES, self.dimensionality], stddev=0.01, mean=0))\n",
    "            tf.summary.histogram('item_features_factors', self.item_features_factors)\n",
    "    \n",
    "    def user_bias(self, user_sparse_features):\n",
    "        with tf.name_scope('B_user'):\n",
    "            return tf.squeeze(tf.nn.embedding_lookup_sparse(\n",
    "                        self.user_features_biases,\n",
    "                        sp_ids=user_sparse_features, sp_weights=None, combiner='sum'))\n",
    "\n",
    "    def item_bias(self, item_sparse_features):\n",
    "        with tf.name_scope('B_item'):\n",
    "            return tf.squeeze(tf.nn.embedding_lookup_sparse(\n",
    "                        self.item_features_biases,\n",
    "                        sp_ids=item_sparse_features, sp_weights=None, combiner='sum'))\n",
    "\n",
    "    def user_item_features_product(self, user_sparse_features, item_sparse_features):\n",
    "        with tf.name_scope('Q_user'):\n",
    "            batch_user_factors = tf.squeeze(tf.nn.embedding_lookup_sparse(\n",
    "                        self.user_features_factors,\n",
    "                        sp_ids=user_sparse_features, sp_weights=None, combiner='sum'))\n",
    "            \n",
    "        with tf.name_scope('P_item'):\n",
    "            batch_item_factors = tf.squeeze(tf.nn.embedding_lookup_sparse(\n",
    "                        self.item_features_factors,\n",
    "                        sp_ids=item_sparse_features, sp_weights=None, combiner='sum'))\n",
    "\n",
    "        with tf.name_scope('dot'):\n",
    "            factors_prediction = tf.reduce_mean(\n",
    "                tf.mul(batch_user_factors, batch_item_factors), reduction_indices=1)\n",
    "        return factors_prediction                \n",
    "    \n",
    "    def predictions(self, user_sparse_features, item_sparse_features):\n",
    "        with tf.name_scope('inference'):\n",
    "            return tf.add(\n",
    "                self.user_item_features_product(user_sparse_features, item_sparse_features), \n",
    "                tf.add(self.user_bias(user_sparse_features), self.item_bias(item_sparse_features), name='biases'),\n",
    "                name='logits')\n",
    "\n",
    "def compute_loss(predictions, targets):\n",
    "    with tf.name_scope('loss'):\n",
    "        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=predictions, targets=targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_predictions_to_hits(all_user_items, all_predicted_values, ground_truth_user_items):\n",
    "    predicted_ratings = all_user_items.assign(predicted_rating=lambda _: all_predicted_values)\n",
    "    predicted_ranks = predicted_ratings.groupby('user')['predicted_rating'].rank(ascending=False, method='max')\n",
    "    predicted_ratings['rank'] = predicted_ranks.values - 1\n",
    "\n",
    "    ground_truth_hits = pd.merge(\n",
    "        left=ground_truth_user_items,\n",
    "        right=predicted_ratings,\n",
    "        on=['user', 'item'], how='left')\n",
    "    return ground_truth_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_predicted_hits(predict_function, ground_truth_df, split_size=1000):\n",
    "    user_ids = ground_truth_df.user.unique()\n",
    "    item_ids = ground_truth_df.item.unique()\n",
    "    user_ids_splits = np.array_split(user_ids, len(user_ids) / split_size)\n",
    "    user_items_splits = (to_all_user_items(user_ids_split, item_ids) for user_ids_split in user_ids_splits)\n",
    "    hits_for_user_splits = [all_predictions_to_hits(\n",
    "            split_user_items, \n",
    "            all_predicted_values=predict_function(split_user_items),\n",
    "            ground_truth_user_items=ground_truth_df[ground_truth_df.user.isin(split_user_items.user.unique())])\n",
    "        for split_user_items in user_items_splits]\n",
    "    return pd.concat(hits_for_user_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Step 0: batch/test log loss = 0.693/0.691, train/test MRR = 0.282/0.063\n",
      "Step 20: batch/test log loss = 0.654/0.659, train/test MRR = 0.496/0.131\n",
      "Step 40: batch/test log loss = 0.637/0.637, train/test MRR = 0.448/0.110\n",
      "Step 60: batch/test log loss = 0.598/0.616, train/test MRR = 0.429/0.108\n",
      "Step 80: batch/test log loss = 0.569/0.608, train/test MRR = 0.426/0.111\n",
      "Step 100: batch/test log loss = 0.575/0.593, train/test MRR = 0.431/0.114\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "N_ITER = 101\n",
    "BATCH_SIZE = 1024\n",
    "N_STEP_SUMMARY = 20\n",
    "LOG_DIR = '/tmp/tfrecs_logs'\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    model = UserItemFeaturesModel(dimensionality=10)\n",
    "    inputs = Placeholders()\n",
    "    \n",
    "    logits = model.predictions(inputs.user_sparse_features, inputs.item_sparse_features)\n",
    "    loss = compute_loss(logits, inputs.ratings)\n",
    "    \n",
    "    tf.summary.scalar('train_loss', loss)\n",
    "    summary = tf.summary.merge_all()\n",
    "    test_summary = tf.summary.scalar('test_loss', loss)\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "                \n",
    "    def perform_step(step, train, test, summary_writer):\n",
    "        batch_samples = sample_batch(train_df, BATCH_SIZE)\n",
    "\n",
    "        _, loss_value, summary_value = sess.run(\n",
    "            fetches=[train_step, loss, summary], \n",
    "            feed_dict=inputs.to_feed_dict(batch_samples, with_ratings=True))\n",
    "        \n",
    "        summary_writer.add_summary(summary_value, global_step=step)\n",
    "\n",
    "        if step % N_STEP_SUMMARY == 0:\n",
    "\n",
    "            test_samples = sample_batch(test_df, BATCH_SIZE)\n",
    "            test_loss_value, test_summary_value = sess.run(\n",
    "                fetches=[loss, test_summary],\n",
    "                feed_dict=inputs.to_feed_dict(test_samples, with_ratings=True))\n",
    "            summary_writer.add_summary(test_summary_value, global_step=step)\n",
    "\n",
    "            # predicting on all users and items\n",
    "            train_hits = all_predicted_hits(\n",
    "                lambda user_items: logits.eval(feed_dict=inputs.to_feed_dict(user_items)),\n",
    "                train_df, split_size=200)\n",
    "\n",
    "            test_hits = all_predicted_hits(\n",
    "                lambda user_items: logits.eval(feed_dict=inputs.to_feed_dict(user_items)),\n",
    "                test_df, split_size=200)\n",
    "            \n",
    "            print('Step %d: batch/test log loss = %.3f/%.3f, train/test MRR = %.3f/%.3f' % (\n",
    "                    step, loss_value, test_loss_value, \n",
    "                    mean_reciprocal_rank(train_hits),\n",
    "                    mean_reciprocal_rank(test_hits)\n",
    "                ))\n",
    "\n",
    "        summary_writer.flush()\n",
    "                \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(LOG_DIR + '/{:%Y%m%d%H%M%S}'.format(dt.datetime.now()), sess.graph)\n",
    "\n",
    "        print('Starting training')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for step in range(N_ITER):\n",
    "            perform_step(step, train_df, test_df, summary_writer)\n",
    "\n",
    "        train_hits = all_predicted_hits(\n",
    "            lambda user_items: logits.eval(feed_dict=inputs.to_feed_dict(user_items)),\n",
    "            train_df, split_size=100)\n",
    "\n",
    "        test_hits = all_predicted_hits(\n",
    "            lambda user_items: logits.eval(feed_dict=inputs.to_feed_dict(user_items)),\n",
    "            test_df, split_size=100)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90570, 5)\n",
      "(9430, 5)\n",
      "0.431066543434\n",
      "0.114040851421\n"
     ]
    }
   ],
   "source": [
    "print(train_hits.shape)\n",
    "print(test_hits.shape)\n",
    "print(mean_reciprocal_rank(train_hits))\n",
    "print(mean_reciprocal_rank(test_hits))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
